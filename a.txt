Brod Net concept
================

The network is going to cover two modes of operation.

1. Mesh network
2. Owerlay network

And should serve the following

1. Verifiable Files
2. Named Files
3. Keyword Searches
4. MeSsages

Units
-----

The source code is divided into following units.

 File       | Description 
-----------:|-------------
[Peers]		| Client evidence. Akafukas.
[Share]		| Searching. Delivery of results.
[Tag]		| Tags hashing. Tags of files and peers. Matching tags.
[Transfer]	| CHK file transfer.
[DataBase]	| Generic 4-dimensional file database.
[NetAddr]	| Network address abstraction.
[Keys]		| Cryptographic operations and data structures.
[Log]		| Centralized logging.
[Test]		| Unit Tests.
[bncommon]	| Routines shared between both programs.
[bnd]		| The Daemon.
[bnctl]		| Managment tool.

[Peers]: Peers.pas
[Share]: Share.pas
[Tag]: Tag.pas
[Transfer]: Transfer.pas
[DataBase]: DataBase.pas
[NetAddr]: NetAddr.pas
[Keys]: Keys.pas
[Log]: Log.pas
[Test]: Test.pas "Unit Tests"
[bncommon]: bncommon.pp
[bnd]: bnd.pp
[bnctl]: bnctl.pp

Daemons and Services
--------------------

Xinetd is going to listen for all connections. Including connections to web 
interface. For protocols incompatible with xinetd, new network daemon is 
going to be written.

Daemon is started by netd with stdin/stdout connected to socket. A packet 
is recieved (rcvmsg) from the socket and parsed. Depending on the type and 
contents of the packet, approportiate action is taken. If reply should be 
sent, new datagram socket is created and the socaddr is used as 
destination. Then the daemon listens for another packet with configurable 
timeout. If no packet was received in time, daemon exits. And netd listens 
again.

There can be possibly multiple instances of brodnetd running, so 
approportiate database locking should be implemented.

### BnCtl

Local node can be controlled by bnctl program.

Usage: bnctl [%1] [%2] [%3] [-stderr] [<switches>]

switch| meaning   | %1 | %2 | %3
------|-----------|----|----|----
-p	| Peer controll
-pa	| add	| netaddr
-pi	| info	| id
-pl	| list
-pakafuka	| do Akafuka now

impl| netaddr syntax	| meaning
----|-----------------|--------
yes	| //ip4/127.0.0.1/32					| IP4, port 32 UDP
no	| //ip6/2001:0db8:85a3:0000:0000:8a2e:0370:7334/32	| IP6, port 32 UDP
no	| //bluetooth/00:10:C6:F7:5B:AC/l2cap/4567	| bluetooth
no	| //char/dev/ttyS0							| character device
no	| //local/tmp/foobar						| unix domain socket

Discovery
---------

The node finds its peers by sending a local area broadcasts (LAND). It is 
performed by sending Akafuka packet to all devices in range of all network 
interfaces.

The second mode of discovery is wide area node discovery (WAND). It is 
performed by sending request to all peers in node list, which 
should reply with list of nodes. The node then tryies to send Akafuka packet 
to discovered nodes directly. If successfull (eg: in Internet), it uses 
them as peers. If unsuccessfull (eg: in Meshnet), it updates its routing 
table.

### Note on key sizes

*deprecated*

2048 RSA signing keys with SHA256 digest are ok (about 0.5kiB). DSA keys are preffered.
The whole hello.dat.gpg has to fit in one UDP packet (max 1kiB).

The hello.dat has one 20B Fingerprint, and like 48 4B Area codes ==212B.

The signature is MAX 512B.

Packet is 725B.

Greetings (Akafuka Fundeluka)
------------------

Akafuka is used to find new peers (LAND) as well as to check 
availability of peers.

Akafuka (and Fundeluka, they are same) consist of:

 - ID of Sender (20B)
 - Average load of the Sender (1B)
 - Socket Address of the Reciever (IPv4 12B, IPv6 24B)

The purpose of the reciever's sockaddr filed
is to inform nodes behind NAT of their external Address.
This could be possibly used for STUN.
It can be null, if unknown (eg: broadcast).

### If node recieves an Akafuka

- it adds the sender to list of peers.

- in cHelloCooldown{ms} since last Hello from the same peer,
  no further actions are performed

- it replies with Fundeluka
 
Areas
-----

Each node has an area record. A node can find its area record from its 
peers. The area record is used to accelerate routing.

The area record is just list of area codes. An area code is 32bit 
number and specifies a geological or fictional location of the node.
There are usually more area codes in area record of a given node.

When there are too much nodes in an area, new area should be created. When 
there are too litle nodes in area, the area code is abadoned.

The area codes could be possibly created and managed autmomatically, but 
now they are managed by administrator.

File Sharing
------------

*unimplemented*

All files in the network have tags. Files are found only by their tags.

Search request (GET) and reply (PUT) is done with packet of the same 
structure. The only difference is pktype field and that fh field is null in 
GET packets.

Searching for a file is performed by sending FileShare.T packet to some 
peers. This packed is Acknowledged. Peers should search in their datastore 
or ask their peers. As soon as they find something, they send back a 
FileShare.T packet. If the search is satisfied, FileTransfer is initiated.

### Avoiding Routing Loop

When a FileShare GET packet arrives, it is forwarded to interested peers 
only if tags in the pachet differ from the ones in the filestore.

If the packet is PUT, search cache is checked instead.
And if we are also interested in resuilts from the serach, we forward the 
same packet back to sender. He adds our id to his search cache.



### Comm

Note: 'tags' is array of hash of tagstring.

1. -> FileShare.T (hash = 0, tags)
2. 
   * <- FileShare.T (hash = 1, tags)
   * <- FileShare.T (hash = 2, tags)
   * <- FileShare.T (hash = 3, tags)
3. -> FileTrans.tYes (hash = 2)
4. 
   * <- FileTrans.tPcs (hash = 2, order = 1, total = 2, pcs=(a,...) )
   * <- FileTrans.tPcs (hash = 2, order = 2, total = 2, pcs=(...) )
5. -> FileTransfer.tYes (hash = a)
6. <- FileTransfer.tData (hash = a, data=(...) )

Tags
----

Every file has tags.
Even nodes have tags.
Tags are used to find files. 

But files hav max of 200 tags (to not fragment search packets).

Tags of a given object are stored in file tags.dat in the object's 
directory. To speed up searching tags are stored in <db>/tag/<taghash> 
files which are file of Keys.tHash.

	files/
	├── tag/
	│   ├── BACABABA
	│   └── 1234FEDC
	├── CA/
	│   └── CAFEBABE12345678/
	│       └── tags.dat
	└── 01/
	    └── 01234567ABCDEF00/
	        └── tags.dat

### Searching

For all tags in the query: FileIDs from <db>/tag/%taghash% are all 
added to in-memory linked-list, but for files already in the list, count 
field is increased and the entry is moved closer to start of the list. 

Finally, the list contains best resuilts near the start.

### Searching

Node recieves a fileshare search. First tag is selected. FileIDs from 
/tag/%taghash% are all added to in-memory linked-list. Next tag is 
selected. Files there are added to the list, but for files already in the 
list count field is increased and the entry is moved closer to start of the 
list.


File Transfer
-------------

[File Transfer][Transfer] is used to copy files or parts of files ower the 
network.

### Parts

Filetransfer answer packets all contain sequence number of part and number 
of total parts. The Transfer takes care of downloading all parts of the 
file. When the whole data object is downloaded, its hash is checked. If the 
hashes do not match, the data object is erased and download is started over 
again. When the download is complete and the hash matched,
other units are notified.

To keep tracks on what parts were downloaded, a parts.dat field is stored 
in files.db. Additionaly an entry to downloadlist.dat is added. Parts of 
the same file are downloaded from the same peer.

### Pieces

Files can be split to pieces. Multiple files can share the same pieces. One 
data object is either File or list of pieces (Pieced file). Pieces are 
normal files. A node tries to download all pieces of file. The lis of 
pieces for Pieced file is downloaded in Parts (described in previous section).

Pieced files can be reassembled on request (after the node has downloaded 
all the pieces). Pieced files are identified by hash of the assembled file. 
The hash can only be checked after all pieces of the file have been 
downloaded. If the hashes do not match, only the Pieced file is erased and 
downloaded again. The already downloaded pieces are left in the files.db.

Pieced files have pieces.dat in the files.db instead of content.dat. And 
files that are pieces of some Pieced file have ref.dat in files.db.

In opposite to Parts, pieces of the same Pieced file can be downloaded from 
multiple peers *at the same time*. Becouse pieces are just normal files.

### Communication

File transfer is initaited by sending a Transfer.tGet packet to peer, who 
should have the data object. The peer sends back either file contents in 
Transfer.tDat or list of pieces in Transfer.tPcs (Pieced file) packet.

If no reply is recieved (packet lost) in time, the tYes packet is sent 
again.

